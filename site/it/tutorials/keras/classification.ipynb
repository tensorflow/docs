{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MhoQ0WE77laV"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "_ckMIh7O7s6D",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "vasWnqRgy1H4",
        "colab": {}
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Classificazione base: Classifica immagini di capi d'abbigliamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Visualizza su TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/it/tutorials/keras/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Esegui in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "<a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/it/tutorials/keras/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Visualizza il sorgente su GitHub</a>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Scarica il notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYzaKBe8YXg0",
        "colab_type": "text"
      },
      "source": [
        "Note: La nostra comunità di Tensorflow ha tradotto questi documenti. Poichè queste traduzioni sono *best-effort*, non è garantito che rispecchino in maniera precisa e aggiornata la [documentazione ufficiale in inglese](https://www.tensorflow.org/?hl=en). \n",
        "Se avete suggerimenti per migliorare questa traduzione, mandate per favore una pull request al repository Github [tensorflow/docs](https://github.com/tensorflow/docs). \n",
        "Per proporsi come volontari alla scrittura o alla review delle traduzioni della comunità contattate la \n",
        "[mailing list docs@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "Questa guida allena un modello di rete neurale a classificare immagini di capi d'abbigliamento, come scarpe da ginnastica e magliette. E' normale che tu non comprenda tutti i dettagli; questa è una panoramica rapidissima di un programma completo TensorFlow con i dettagli spiegati durante il percorso.\n",
        "\n",
        "Questa guida usa [tf.keras](https://www.tensorflow.org/guide/keras), un'API di alto livello per costruire ed addestrare modelli in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jL3OqFKZ9dFg",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzLKpmZICaWN",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Importare il dataset Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "Questa guida usa il dataset [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) che contiene  70,000 immagini in toni di grigio di 10 categorie. Le immagini mostrano singoli articoli di abbigliamento a bassa risoluzione (28 per 28 pixel), come visibile sotto:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figura 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST va inteso come l'equivalente del classico dataset  [MNIST](http://yann.lecun.com/exdb/mnist/) —spesso usato come \"Hello, World\" dei programmi di machine learning per la visione computerizzata. Il dataset MNIST contiene immagini di caratteri scritti a mano (0, 1, 2, ecc.) in un formato identico a quello degli articoli di abbigliamento che useremo qui.\n",
        "\n",
        "Questa guida usa Fashion MNIST per varietà, e perchè costituisce un problema leggermente più impegnativo del tipico MNIST. Entrambe i dataset sono relativamente piccoli e sono usati per verificare che un algoritmo lavori come previsto. Sono un buon punto di partenza per provare e correggere gli errori del codice.\n",
        "\n",
        "Qui, 60,000 immagini sono utilizzate per addestrare la rete e 10,000 immagini per valutare quanto accuratamente la rete ha imparato a classificare immagini. Potete accedere al Fashion MNIST direttamente da  TensorFlow. Importare e caricare i dati Fashion MNIST direttamente da  TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Il caricamento dei dati restituisce quattro vettori NumPy:\n",
        "\n",
        "* I vettori `train_images` e `train_labels` sono gli *insiemi di addestramento*—i dati che il modello usa per imparare.\n",
        "* Il modello è verificato con l' *insieme di verifica*, i vettori `test_images`, e `test_labels`.\n",
        "\n",
        "Le immagini sono vettori di 28x28 NumPy, in cui i valori dei pixel vanno da 0 a 255. Le *etichette* sono un vettore di interi, da 0 a 9. Esse corrispondono alle *classi* di capi di abbigliamento rappresentate dalle immagini:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Ogni immagine è mappata in una singola etichetta. Dato che i *nomi delle classi* non sono inclusi nel dataset, vengono memorizzati qui, per usarli successivamente durante la visualizzazione delle immagini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjnLH5S2CaWx",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Esplorare i dati\n",
        "\n",
        "Esploriamo il formato dei dati prima di allenare il modello. Il seguito mostra che ci sono 60,000 immagini nell'insieme di addestramento, con ciascuna immagine rappresentata con 28 x 28 pixel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zW5k_xz1CaWX",
        "colab": {}
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Analogamente, nell'insieme di addestramento, ci sono 60,000 etichette:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TRFYHB2mCaWb",
        "colab": {}
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "Ogni etichetta è un intero tra 0 e 9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XKnCTHz4CaWg",
        "colab": {}
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "Ci sono 10,000 immagini nel insieme di verifica. Di nuovo, ogni immagine è rappresentata come 28 x 28 pixel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2KFnYlcwCaWl",
        "colab": {}
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rd0A0Iu0CaWq"
      },
      "source": [
        "Ed l'insieme di verifica contiene 10,000 etichette di immagini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJmPr5-ACaWn",
        "colab": {}
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Pre-elaborare i dati\n",
        "\n",
        "Prima di allenare la rete, i dati devono essere pre-elaborati. Osservando la prima immagine dell'insieme di addestramento, si noterà che i valori dei pixel cadono nell'intervallo da 0 a 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m4VEw8Ud9Quh",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "Questi valori vanno scalati in un intervallo tra 0 e 1 prima di darli in pasto al modello della rete. Per fare ciò, si dividono i valorei per 255. E' importante che l'*insieme di addestramento* ed l'*insieme di verifica* siano pre-elaborati nello stesso modo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW5WzIPlCaWv",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "Per verificare che i dati siano nella forma corretta e che tutto sia pronto per costruire e allenare la rete, visualizziamo le prime 25 immagini del  *insieme di addestramento* e visualizziamo il nome della classe sotto a ciascuna immagine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oZTImqg_CaW1",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Costruire il modello\n",
        "\n",
        "La costruzione della rete neurale richiede di configurare i livelli del modello, quindi la compilazione del modello."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Inizializzare i livelli\n",
        "\n",
        "L'elemento costruttivo di base di una rete neurale è il *livello*. I livelli estraggono rappresentazioni dai dati con cui vengono alimentati. Sperabilmente, queste rappresentazioni sono significative per il problema che si sta trattando.\n",
        "\n",
        "La maggior parte del deep learning consiste nel collegare tra loro livelli semplici. La maggior parte dei livelli, come `tf.keras.layers.Dense`, hanno parametri che sono imparati durante l'allenamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ODch-OFCaW4",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "Il primo livello in questa rete, `tf.keras.layers.Flatten`, trasforma il formato delle immagini da un array bi-dimensionale (di 28 per 28 pixel) in un array uni-dimensionale (di 28 * 28 = 784 pixel). Pensate a questi livelli come righe non impilate di pixel dell'immagine. Questo livello non ha parametri da imparare; esso si limita a rifirmattare i dati.\n",
        "\n",
        "Dopo la normalizzazione dei pixel, la rete consiste di due livelli `tf.keras.layers.Dense`. Questi sono livelli neurali strettamente connessi, o completamente connessi. Il primo livello `Denso` ha 128 nodi  (o neuroni). Il secondo (ed ultimo) livello è un livello *softmax* a 10 nodi che restituisce un vettore di 10 valori di probabilità la cui somma è 1. Ogni nodo contiene un valore che indica la probabilità che l'immagine corrente appartenga ad una delle 10 classi.\n",
        "\n",
        "### Compilare il modello\n",
        "\n",
        "Prima che il modello sia pronto per l'apprendimento, è necessaria qualche impostazione in più. Queste sono aggiunte durante i passi di *compilazione* del modello:\n",
        "\n",
        "* *Funzione perdita* —Misura quanto è accurato il modello durante l'apprendimento. La volontà è di minimizzare questa funzione per \"dirigere\" il modello nella giusta direzione.\n",
        "* *Ottimizzatore* —Indica com'è aggiornato il modello sulla base dei dati che tratta e della sua funzione perdita.\n",
        "* *Metriche* —Usate per monitorare i passi di addestramento e verifica. L'esempio seguente usa come *accuratezza*, la frazione delle immagini che sono classificate correttamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Addestrare il modello\n",
        "\n",
        "L'addestramento del modello di rete neurale richiede i seguenti passi:\n",
        "\n",
        "1. Alimentare il modello con i dati di addestramento. In questo esempio, i dati di addestramento sono nei vettori `train_images` e `train_labels`.\n",
        "2. Il modello impara ad associare immagini ed etichette.\n",
        "3. Chiedere al modello di fare previsioni su un insieme di prova—in questo esempio, il vettore `test_images`.\n",
        "4. Verificare che le previsioni corrispondano alle etichette del vettore `test_labels`.\n",
        "Per iniziare l'addestramento, chiamare il metodo `model.fit`—chiamato così perchè \"allena\" il modello sui dati di addestramento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvwvpA64CaW_",
        "colab": {}
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "Mentre il modello si allena, vengono visualizzate le metriche di perdita e accuratezza. Questo modello raggiunge un'accuratezza di circa 0.88 (o 88%) sui dati di addestramento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Valutare l'accuratezza\n",
        "\n",
        "Successivamente, valutare come si comporta il modello sul dataset di test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VflXLEeECaXC",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "Per scoprire che l'accuratezza sul datase di test è leggermente inferiore rispetto a quella sul dataset di addestramento. Questa differenza tra l'accuratezza in addestramento e l'accuratezza in test rappresenta l' *overfitting*. L'overfitting è quando un modello di machine learning ha prestazioni peggiori su input nuovi, mai visti prima, che sui dati di addestramento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Fare previsioni\n",
        "\n",
        "Una volta addestrato il modello, puoi usarlo per fare previsioni su altre immagini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gl91RPhdCaXI",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Qui, il modello ha previsto l'etichetta per ciascuna immagine nell'insieme di test. Diamo un'ochiata alla prima previsione:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DmJEUinCaXK",
        "colab": {}
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "Una prevsione è un vettore di 10 numeri. Essi rappresentano la \"confidenza\" del modello che l'immagine corrisponda a ciascuno dei 10 diversi articoli di abbigliamento. E si può vedere quale etichetta ha il valore più alto di confidenza:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsqenuPnCaXO",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "Così, il modello è più condidente che l'immagine sia uno stivaletto, o `class_names[9]`. L'esame dell'etichetta di test ostra che questa classificazione è corretta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sd7Pgsu6CaXP",
        "colab": {}
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Mettendo ciò in forma grafica, si può osservare l'insieme completo delle previsioni sulle 10 classi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DvYmmrpIy6Y1",
        "colab": {}
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "Osservimo la 0esima immagine, le previsioni, e il vettore delle previsioni. Le etichette previste correttamente sono in blu e le previsioni non corrette sono in rosso. Il numero da la percentuale (su 100) dell'etichetta prevista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HV5jw-5HwSmO",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ko-uzOufSCSe",
        "colab": {}
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "Rappresentiamo diverse immagini con le rispettive previsioni. Notiamo che il modello può sbagliare anche quando è molto confidente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hQlnbqaw2Qu_",
        "colab": {}
      },
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R32zteKHCaXT"
      },
      "source": [
        "Infine, usiamo il modello addestrato per fare una previsione su una singola immagine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yRJ7JU7JCaXT",
        "colab": {}
      },
      "source": [
        "# Grab an image from the test dataset.\n",
        "img = test_images[1]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vz3bVp21CaXV"
      },
      "source": [
        "I modelli `tf.keras` sono ottimizzati per fare previsioni su *batch*, o collezioni, di esempi in una volta. Di conseguenza, anche se state usando una singola immagine, è necessario aggiungerla ad una lista:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lDFh5yF_CaXW",
        "colab": {}
      },
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Ed ora andiamo a prevedere l'etichetta corretta per questa immagine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_rzNSdrCaXY",
        "colab": {}
      },
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Ai-cpLjO-3A",
        "colab": {}
      },
      "source": [
        "plot_value_array(1, predictions_single[0], test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`model.predict` restituisce una lista di liste—una lista per ogni immagine nel batch di dati. Prendiamo la previsione per la nostra (unica) immagine nel batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tRmdq_8CaXb",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "E il modello prevede l'etichetta secondo le aspettative."
      ]
    }
  ]
}