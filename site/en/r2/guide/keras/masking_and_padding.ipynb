{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eIrvnAbGZ1wP"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "_A4IPZ-WZ9H7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WpaDQG8VaYFO"
      },
      "source": [
        "# Masking and Padding\n",
        "\n",
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/beta/guide/keras/masking_and_padding\"\u003e\n",
        "    \u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003e\n",
        "    View on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/guide/keras/masking_and_padding.ipynb\"\u003e\n",
        "    \u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003e\n",
        "    Run in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/keras/masking_and_padding.ipynb\"\u003e\n",
        "    \u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003e\n",
        "    View source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/guide/keras/masking_and_padding.ipynb\"\u003e\n",
        "    \u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003e\n",
        "    Download notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jsI2RsuQaiZG"
      },
      "source": [
        "For sequential data input, it is very common that the each individual entry has different length in the sequence length dimension. Consider the following example with text input.\n",
        "\n",
        "```\n",
        "[\n",
        "  [\"It\", \"is\", \"a\", \"nice\", \"weather\", \"today\"],\n",
        "  [\"How\", \"are\", \"you\", \"doing\", \"today\"],\n",
        "  [\"Hello\", \"world\", \"!\"]\n",
        "]\n",
        "```\n",
        "\n",
        "After the vocab lookup, the data might be converted to numerical form like:\n",
        "\n",
        "```\n",
        "[\n",
        "  [83, 91, 1, 645, 1253, 927],\n",
        "  [73, 8, 3215, 55, 927],\n",
        "  [71, 1331, 4231]\n",
        "]\n",
        "```\n",
        "\n",
        "The data is a 2D list, the individual item within it has length [6, 5, 3]. Since the input data for the model need to be to be in a uniformed shape, which means the data that is shorter than the lengest item need to be padded with some placeholder.\n",
        "\n",
        "Keras provides an API for user to easily pad their data to the same length by [tf.keras.preprocessing.sequence.pad_sequences](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGJH5EKYoSHZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wJEBe8hTlB6W"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "!pip install tensorflow==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5ShanCQ_pSPO"
      },
      "source": [
        "## Pad sequence data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xI-lHnyxfa2T"
      },
      "outputs": [],
      "source": [
        "raw_inputs = [\n",
        "  [83, 91, 1, 645, 1253, 927],\n",
        "  [73, 8, 3215, 55, 927],\n",
        "  [711, 632, 71]\n",
        "]\n",
        "\n",
        "# By default, the API will pad 0s, and it is configurable with \"value\" parameter.\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs, padding='post')\n",
        "\n",
        "print(padded_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HyHf90yAqkMr"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o16pUIBLgc_Q"
      },
      "source": [
        "Now the data have the uniformed sequence length, the model need to be informed that some part of the data is actually padding and need to be ignored. The mechanism is \u003cb\u003eMasking\u003c/b\u003e.\n",
        "\n",
        "There are two ways to introduce mask within Keras:\n",
        "- Add a [tf.keras.layers.Masking](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Masking).\n",
        "- Config an [Embedding layer](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Embedding) with `mask_zero` = True.\n",
        "\n",
        "Under the hood, Keras will create a mask tensor (2D with shape [batch, sequence_length]), and attach it with tensor output from masking or embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rYXQ589PkC0P"
      },
      "outputs": [],
      "source": [
        "embedding = layers.Embedding(5000, 16, mask_zero=True)\n",
        "masked_output = embedding(padded_inputs)\n",
        "\n",
        "print(masked_output._keras_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-0VVscXQm1D1"
      },
      "outputs": [],
      "source": [
        "masking_layer = layers.Masking()\n",
        "# Simulate the embedding lookup by expand the 2D input to 3D and make the\n",
        "# embedding dimension to be 10.\n",
        "unmasked_embedding = tf.cast(\n",
        "    tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]),\n",
        "    tf.float32)\n",
        "\n",
        "masked_embedding = masking_layer(unmasked_embedding)\n",
        "print(masked_embedding._keras_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RL2vsiCBmVck"
      },
      "source": [
        "As you can see from the printed result, the mask is a 2D boolean tensor, with shape `[batch, sequence_length]`, each individual \"False\" means the data is not a real input, and should be ignored during process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s4jsu6oTrl2f"
      },
      "source": [
        "## Handle masks in custom layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0KgNt7fvm0Jx"
      },
      "source": [
        "The mask will be propagate through the network, for any layer that uses mask (for example, RNN layers), Keras will fetch the ._keras_mask tensor and pass the mask as a key word argument to `call()`.\n",
        "\n",
        "For any layer that produces a tensor with different rank with regard to the input, for example RNN layer might return 2D tensor while the input is 3D, it will need to overwrite the `layer.compute_mask()` method to produce a new mask given the input. This is applicable for layer with multiple input/output, for example `tf.keras.layers.Concatenate`, it needs to recompute the mask by applying `tf.concat` to the two input masks.\n",
        "\n",
        "Most of layers don't worry about the mask, the default behavior is just pass the mask through."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gaS_7dXyr-Z0"
      },
      "outputs": [],
      "source": [
        "class Split(tf.keras.layers.Layer):\n",
        "  \"\"\"Split the input tensor into 2 tensors among the axis parameter.\"\"\"\n",
        "\n",
        "  def __init__(self, axis=1, **kwargs):\n",
        "    self.axis = axis\n",
        "    super(Split, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Expect the input to be 3D and mask to be 2D, split the input tensor into 2\n",
        "    # among the `axis`.\n",
        "    return tf.split(inputs, 2, axis=self.axis)\n",
        "    \n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    # Also split the mask into 2 if it presents.\n",
        "    if mask is None:\n",
        "      return None\n",
        "    return tf.split(mask, 2, axis=self.axis)\n",
        "\n",
        "first_half, second_half = Split()(masked_embedding)\n",
        "print(first_half._keras_mask)\n",
        "print(second_half._keras_mask)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Masking and Padding",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1fILMwbbLGNf7x1l0Cf1pi-tziO3fcrbO",
          "timestamp": 1561414475334
        }
      ],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
