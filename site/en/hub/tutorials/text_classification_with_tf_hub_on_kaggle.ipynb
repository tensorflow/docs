{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KUu4vOt5zI9d"
      },
      "outputs": [],
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9PfyoQ2rH_"
      },
      "source": [
        "# How to solve a problem on Kaggle with TF-Hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub_on_kaggle\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/hub/tutorials/text_classification_with_tf_hub_on_kaggle.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/google/nnlm-en-dim128/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "556YQZLUO4Ih"
      },
      "source": [
        "TF-Hub is a platform to share machine learning expertise packaged in reusable resources, notably pre-trained **modules**. In this tutorial, we will use a TF-Hub text embedding module to train a simple sentiment classifier with a reasonable baseline accuracy. We will then submit the predictions to Kaggle.\n",
        "\n",
        "For more detailed tutorial on text classification with TF-Hub and further steps for improving the accuracy, take a look at [Text classification with TF-Hub](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/text_classification_with_tf_hub.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DN769E2O_R"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KyLct9rq0lo"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7hy0bhngTUp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvgBdeMsuu_3"
      },
      "source": [
        "Since this tutorial will be using a dataset from Kaggle, it requires [creating an API Token](https://github.com/Kaggle/kaggle-api) for your Kaggle account, and uploading it to the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI7C-Zc4urOH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Upload the API token.\n",
        "def get_kaggle():\n",
        "  try:\n",
        "    import kaggle\n",
        "    return kaggle\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "  token_file = pathlib.Path(\"~/.kaggle/kaggle.json\").expanduser()\n",
        "  token_file.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    raise ValueError(\"Could not find kaggle token.\")\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  token_content = uploaded.get('kaggle.json', None)\n",
        "  if token_content:\n",
        "    token_file.write_bytes(token_content)\n",
        "    token_file.chmod(0o600)\n",
        "  else:\n",
        "    raise ValueError('Need a file named \"kaggle.json\"')\n",
        "  \n",
        "  import kaggle\n",
        "  return kaggle\n",
        "\n",
        "\n",
        "kaggle = get_kaggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OPyVxHuiTEE"
      },
      "source": [
        "# Getting started\n",
        "\n",
        "## Data\n",
        "We will try to solve the [Sentiment Analysis on Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) task from Kaggle. The dataset consists of syntactic subphrases of the Rotten Tomatoes movie reviews. The task is to label the phrases as **negative** or **positive** on the scale from 1 to 5.\n",
        "\n",
        "You must [accept the competition rules](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) before you can use the API to download the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "rKzc-fOGV72G"
      },
      "outputs": [],
      "source": [
        "SENTIMENT_LABELS = [\n",
        "    \"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"\n",
        "]\n",
        "\n",
        "# Add a column with readable values representing the sentiment.\n",
        "def add_readable_labels_column(df, sentiment_value_column):\n",
        "  df[\"SentimentLabel\"] = df[sentiment_value_column].replace(\n",
        "      range(5), SENTIMENT_LABELS)\n",
        "    \n",
        "# Download data from Kaggle and create a DataFrame.\n",
        "def load_data_from_zip(path):\n",
        "  with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
        "    name = zip_ref.namelist()[0]\n",
        "    with zip_ref.open(name) as zf:\n",
        "      return pd.read_csv(zf, sep=\"\\t\", index_col=0)\n",
        "\n",
        "\n",
        "# The data does not come with a validation set so we'll create one from the\n",
        "# training set.\n",
        "def get_data(competition, train_file, test_file, validation_set_ratio=0.1):\n",
        "  data_path = pathlib.Path(\"data\")\n",
        "  kaggle.api.competition_download_files(competition, data_path)\n",
        "  competition_path = (data_path/competition)\n",
        "  competition_path.mkdir(exist_ok=True, parents=True)\n",
        "  competition_zip_path = competition_path.with_suffix(\".zip\")\n",
        "\n",
        "  with zipfile.ZipFile(competition_zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(competition_path)\n",
        "  \n",
        "  train_df = load_data_from_zip(competition_path/train_file)\n",
        "  test_df = load_data_from_zip(competition_path/test_file)\n",
        "\n",
        "  # Add a human readable label.\n",
        "  add_readable_labels_column(train_df, \"Sentiment\")\n",
        "\n",
        "  # We split by sentence ids, because we don't want to have phrases belonging\n",
        "  # to the same sentence in both training and validation set.\n",
        "  train_indices, validation_indices = model_selection.train_test_split(\n",
        "      np.unique(train_df[\"SentenceId\"]),\n",
        "      test_size=validation_set_ratio,\n",
        "      random_state=0)\n",
        "\n",
        "  validation_df = train_df[train_df[\"SentenceId\"].isin(validation_indices)]\n",
        "  train_df = train_df[train_df[\"SentenceId\"].isin(train_indices)]\n",
        "  print(\"Split the training data into %d training and %d validation examples.\" %\n",
        "        (len(train_df), len(validation_df)))\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = get_data(\n",
        "    \"sentiment-analysis-on-movie-reviews\",\n",
        "    \"train.tsv.zip\", \"test.tsv.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq_EyS1BEyK"
      },
      "source": [
        "Note: In this competition the task is not to rate entire reviews, but individual phrases from within the reviews. This is a much harder task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hgsiWNq5y9"
      },
      "outputs": [],
      "source": [
        "train_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPuHgx3BWBOg"
      },
      "source": [
        "## Training an Model\n",
        "\n",
        "*Note: We could model this task also as a regression, see [Text classification with TF-Hub](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/text_classification_with_tf_hub.ipynb).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23U30yEkVq4w"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, hub_url):\n",
        "    super().__init__()\n",
        "    self.hub_url = hub_url\n",
        "    self.embed = hub.load(self.hub_url).signatures['default']\n",
        "    self.sequential = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(500),\n",
        "      tf.keras.layers.Dense(100),\n",
        "      tf.keras.layers.Dense(5),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    phrases = inputs['Phrase'][:,0]\n",
        "    embedding = 5*self.embed(phrases)['default']\n",
        "    return self.sequential(embedding)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"hub_url\":self.hub_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE--GDMM2tSp"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "model.compile(\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.optimizers.Adam(), \n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRr-lvhstiNw"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=dict(train_df), y=train_df['Sentiment'],\n",
        "          validation_data=(dict(validation_df), validation_df['Sentiment']),\n",
        "          epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8j7YTRSe7Pj"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "Run predictions for the validation set and training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGqVNSl87bgN"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbLg5LzGwAfC"
      },
      "outputs": [],
      "source": [
        "train_eval_result = model.evaluate(dict(train_df), train_df['Sentiment'])\n",
        "validation_eval_result = model.evaluate(dict(validation_df), validation_df['Sentiment'])\n",
        "\n",
        "print(f\"Training set accuracy: {train_eval_result[1]}\")\n",
        "print(f\"Validation set accuracy: {validation_eval_result[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2IsTF5vuAX"
      },
      "source": [
        "## Confusion matrix\n",
        "\n",
        "Another very interesting statistic, especially for multiclass problems, is the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). The confusion matrix allows visualization of the proportion of correctly and incorrectly labelled examples. We can easily see how much our classifier is biased and whether the distribution of labels makes sense. Ideally the largest fraction of predictions should be distributed along the diagonal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKUnJFYY8bO_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(dict(validation_df))\n",
        "predictions = tf.argmax(predictions, axis=-1)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjAs8W_Z9BvP"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(validation_df['Sentiment'], predictions)\n",
        "cm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT71CtArpsKz"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(\n",
        "    cm, annot=True,\n",
        "    xticklabels=SENTIMENT_LABELS,\n",
        "    yticklabels=SENTIMENT_LABELS)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pic7o2m04weY"
      },
      "source": [
        "We can easily submit the predictions back to Kaggle by pasting the following code to a code cell and executing it:\n",
        "\n",
        "``` python\n",
        "test_predictions = model.predict(dict(test_df))\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "\n",
        "result_df[\"Predictions\"] = test_predictions\n",
        "\n",
        "result_df.to_csv(\n",
        "    \"predictions.csv\",\n",
        "    columns=[\"Predictions\"],\n",
        "    header=[\"Sentiment\"])\n",
        "kaggle.api.competition_submit(\"predictions.csv\", \"Submitted from Colab\",\n",
        "                              \"sentiment-analysis-on-movie-reviews\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50BLu-JX_dlm"
      },
      "source": [
        "After submitting, [check the leaderboard](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/leaderboard) to see how you did."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_with_tf_hub_on_kaggle.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
