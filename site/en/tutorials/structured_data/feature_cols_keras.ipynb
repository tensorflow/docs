{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20181115 - TensorFlow Feature Columns + Keras Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5HlLYbGjXlNC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifying structured data with tf.keras\n",
        "\n",
        "In this tutorial we will learn how to make predictions on structured data (meaning, a CSV file, or a spreadsheet). We will use a small [dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) provided by the Cleveland Clinic Foundation for Heart Disease. There are 303 rows and 14 columns. Each row describes a patient, and each column describes a feature. We will use this information to predict whether a patient has heart disease."
      ]
    },
    {
      "metadata": {
        "id": "DJ3sfuNZdz8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import pprint\n",
        "\n",
        "from tensorflow.python.feature_column import feature_column_v2 as fc\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfaButMHhUWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://storage.googleapis.com/amitpatankar-datasets/heart-disease-uci.zip'\n",
        "!unzip -o 'heart-disease-uci.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6Dud0Jrs8C9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is a [description](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/heart-disease.names) of this dataset:\n",
        "\n",
        ">Column| Description| Feature Type | Data Type\n",
        ">------------|--------------------|----------------------|-----------------\n",
        ">Age | Age in years | Numerical | integer\n",
        ">Sex | (1 = male; 0 = female) | Categorical | integer\n",
        ">CP | Chest pain type (0, 1, 2, 3, 4) | Categorical | integer\n",
        ">Trestbpd | Resting blood pressure (in mm Hg on admission to the hospital) | Numerical | integer\n",
        ">Chol | Serum cholestoral in mg/dl | Numerical | integer\n",
        ">FBS | (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) | Categorical | integer\n",
        ">RestECG | Resting electrocardiographic results (0, 1, 2) | Categorical | integer\n",
        ">Thalach | Maximum heart rate achieved | Numerical | integer\n",
        ">Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical | integer\n",
        ">Oldpeak | ST depression induced by exercise relative to rest | Numerical | integer\n",
        ">Slope | The slope of the peak exercise ST segment | Numerical | float\n",
        ">CA | Number of major vessels (0-3) colored by flourosopy | Numerical | integer\n",
        ">Thal | 3 = normal; 6 = fixed defect; 7 = reversable defect | Categorical | string\n",
        ">Target | Diagnosis of heart disease (1 = true; 0 = false) | Classification | integer"
      ]
    },
    {
      "metadata": {
        "id": "4Ibn7QnEX4gT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Explore the data with Pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "wLWAfdWfXVzW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('heart-disease-uci/heart_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6rd4iYHR-5f_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inspect the first few rows:"
      ]
    },
    {
      "metadata": {
        "id": "y2aChrIf-4di",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8u4UAMOCtqar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can use ```describe``` to see summary statistics about our dataset:"
      ]
    },
    {
      "metadata": {
        "id": "owTrPBB0tWaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.describe(include=\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPNEgcD4aDz5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see there are 14 columns. The first 13 are features, and the last is the target (or class label) we want to predict. There are both numeric faetures (like age) and categorical features (like sex)."
      ]
    },
    {
      "metadata": {
        "id": "SUngUoCmhL70",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the dataset\n",
        "\n",
        "Here, we'll use tf.data to load this CSV file using the [make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) utility. \n"
      ]
    },
    {
      "metadata": {
        "id": "Y0etlKGx_2IP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.experimental.make_csv_dataset('heart-disease-uci/heart_train.csv', header=True, label_name='target', batch_size=32)\n",
        "\n",
        "# let's cast our labels to float (to prevent model training failure later on)\n",
        "dataset = dataset.map(lambda features,labels: (features, tf.to_float(labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_TnHWIuGDzMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is an example of how to use this dataset:"
      ]
    },
    {
      "metadata": {
        "id": "a4epTk3VfSDW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we'll use pprint here as it makes large dictionary print-outs more human readable\n",
        "for features, labels in dataset.take(1):\n",
        "  pprint.pprint(features)\n",
        "  print()\n",
        "  print(repr(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FTWnnbdmXt_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking above, we can see that we now have a dictionary of tensors."
      ]
    },
    {
      "metadata": {
        "id": "vzVQMvg0T-h0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "  ## Transform with FeatureColumns\n",
        "\n",
        "You can think of feature columns as the itermediearies between the raw data in your CSV and the model that will process them. \n",
        "\n",
        "Note: Feature Columns are only used when working with structured data. If you're classifying images, for example, you can skip this step.\n",
        "\n",
        "The dataset we created above generates dictionaries of feature tensors and labels. Now, we will use feature columns to represent these in a way that is meaningful to our model.\n",
        "\n",
        "A feature_column is a configuration object. It doesn’t hold any data itself, but it tells our model how to transform the raw input data into a useful format. "
      ]
    },
    {
      "metadata": {
        "id": "LBotl6Jw321p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO: explain different types of FCs."
      ]
    },
    {
      "metadata": {
        "id": "vOyu1SUxfp1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a list of all our column names\n",
        "HEADERS = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "\n",
        "# print our list of columns\n",
        "HEADERS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RP5xtO65bPS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create lists of various feature types\n",
        "NUMERICAL_COLUMNS = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']\n",
        "STRING_COLUMNS = ['thal']\n",
        "BUCKETIZED_COLUMNS = ['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gu-dT8cfx21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for our categorical features we will create a list of tuples, which contain the column name and the number of buckets\n",
        "CATEGORICAL_COLUMNS = [('sex',2), ('cp',5), ('fbs',2), ('restecg',3), ('exang',2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frKHGcx8ybwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have appropriately separated our features, we can define appropriate feature columns. \n",
        "\n",
        "We'll create a list to store our newly created feature columns in."
      ]
    },
    {
      "metadata": {
        "id": "k1nazg_j5sUa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list to store our feature columns in\n",
        "feature_columns = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ImxRFLKjjeH9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numeric Columns\n",
        "\n",
        "Data that is already numeric is straightforward, we just use  ```numeric_column```. The code below iterates through the numerical features in our dataset and appends numeric feature columns to our feature_columns list.\n"
      ]
    },
    {
      "metadata": {
        "id": "QNf_SkV2kZCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUMERICAL_COLUMNS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CTvaRbInjIO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for header in NUMERICAL_COLUMNS:\n",
        "  feature_columns.append(fc.numeric_column(header))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2h4S-JNdzJSJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You’ll note that all we’ve done here is define a type of feature, and we haven’t passed any of our data into this feature yet, it's just a configuration object.\n",
        "\n",
        "It's worth noting that transformations that are applied by feature columns become part of the model’s graph, and are therefore exported with the SavedModel. So it is reccommended to push any transformations that should be applied to data during training and inference into feature_columns."
      ]
    },
    {
      "metadata": {
        "id": "5WGd4dNVjgWl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TODO: explain Categorical Identity Column\n",
        "\n",
        "In a categorical identity column, each bucket represents a single, unique integer, this is commonly reffered to as one-hot encoding. For example, let's say you want to represent the integer range [0, 4). That is, you want to represent the integers 0, 1, 2 or 3. In this case, the categorical identity mapping looks like this:\n",
        "\n",
        "A categorical identity column mapping. Note that this is a one-hot encoding, not a binary numerical encoding."
      ]
    },
    {
      "metadata": {
        "id": "SsdgD31_kXay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CATEGORICAL_COLUMNS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aPdDyc60lvlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for header, num_buckets in CATEGORICAL_COLUMNS:\n",
        "    \n",
        "    # create categorical identity feature column\n",
        "    cci = fc.categorical_column_with_identity(header, num_buckets=num_buckets)\n",
        "    \n",
        "    # create an indicator column to generate a mulit-hot representation\n",
        "    indicator = fc.indicator_column(cci)\n",
        "    \n",
        "    # append our categorical feature columns\n",
        "    feature_columns.append(indicator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtgaaRGmNzkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Using Indicator Columns\n",
        "\n",
        "In the above example we have taken our one-hot encoded categorical identity column and used this as an input to a indicator column. \n",
        "Indicator columns never work on the raw features themselves but instead take categorical columns as an input and allow us to encode a multi-hot representation."
      ]
    },
    {
      "metadata": {
        "id": "kn41xDT6j1Lt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Categorical Column\n",
        "We cannot input strings directly to a model. Instead, we must first map strings to numeric or categorical values. Categorical vocabulary columns provide a good way to represent strings as a one-hot vector. \n"
      ]
    },
    {
      "metadata": {
        "id": "OUwQxEgskT1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STRING_COLUMNS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jas7MJs-kK4g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for header in STRING_COLUMNS:\n",
        "  \n",
        "  # list of words within our 'thal' variable\n",
        "  vocabulary_list = ['normal', 'fixed', 'reversible']\n",
        "  \n",
        "  # create categorical vocabulary feature column\n",
        "  ccv = fc.categorical_column_with_vocabulary_list(header, vocabulary_list=vocabulary_list)\n",
        "  \n",
        "  # \n",
        "  embedding = fc.embedding_column(ccv, dimension=3)\n",
        "  \n",
        "  # append our categorical vocabulary embedding to our list\n",
        "  feature_columns.append(embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BTcSovEI0xlF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\**To learn more about embeddings, see the tutorial linked from the **Next Steps** section at the base of this colab*\n"
      ]
    },
    {
      "metadata": {
        "id": "AoMjJO8-JqiA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's print out a description of our feature columns\n",
        "for feature_column in feature_columns:\n",
        "  print(feature_column)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1k3mDb1WzHOh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So now we have configured all of our features, these will become the first layer of our model using a FeatureLayer. When we train our model, this first layer will act like any other keras layer, but it’s primary role will be to take the raw data and transform it into the appropriate representations that our neural net is expecting. This layer will also handle creating and training our embeddings.\n",
        "\n",
        "So, if you have data that needs transformation before it fits into a model - maybe it’s categorical or has string names and vocabularies - you can use feature_columns to handle those transformations batch by batch in TensorFlow, rather than having a whole separate pipeline to do feature transformations in memory. TensorFlow provides many feature columns, and even ways to combine individual columns into more complex representations of the data that your model can learn. \n"
      ]
    },
    {
      "metadata": {
        "id": "ccIbLRvU_tS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_layer = fc.FeatureLayer(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITSoK3P-W--u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define and compile our model"
      ]
    },
    {
      "metadata": {
        "id": "joDxYMPrXgQG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we will use a simple sequential model. Notice the first layer!"
      ]
    },
    {
      "metadata": {
        "id": "W18ov9ZDXo93",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ot2HaDiXXzVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss=tf.keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxkySE7gXgo_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train our model\n",
        "\n",
        "Given the small size of our dataset, we will train for 5 epochs."
      ]
    },
    {
      "metadata": {
        "id": "V9NHKhWIYK3h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "  print (\"Epoch {}:\", epoch)\n",
        "  model.fit(dataset, steps_per_epoch=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ktHjtjL4mEV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looking at the above, we can see that our model converges quickly on this small and simple dataset "
      ]
    },
    {
      "metadata": {
        "id": "N5HQ17FiXg1g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validating our Model\n",
        "\n",
        "TODO: one sentence on test data and creating a new tf.data dataset"
      ]
    },
    {
      "metadata": {
        "id": "RG8MHQojYdJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read in our test data with tf.data\n",
        "# our test data has no header row, so we will assign the column names using the HEADERS list from earlier\n",
        "test_data = tf.data.experimental.make_csv_dataset('heart-disease-uci/heart_test.csv', column_names=HEADERS, header=False, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BwW9NQdAYdcY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note here that because we took care of our data transformations using feature columns, we know that the transformation of our input validation data will happen in the same way as it did for our training data, which is critical to ensuring repeatable results."
      ]
    },
    {
      "metadata": {
        "id": "P7o-RDPgYyjz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data, steps=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4viqaGsYdmn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we will save and export our model. Once this is done, we can either load it back into our Python program for later use, or serve it with tf.serving, or run it in a webpage using TensorFlow.js.\n"
      ]
    },
    {
      "metadata": {
        "id": "RLIP6MDmYdw8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Export using SavedModel\n",
        "\n",
        "TensorFlow provides a model saving format that works across the suite of TensorFlow products, including TensorFlow serving and TensorFlow.JS. \n",
        "\n",
        "The TensorFlow SavedModel includes a checkpoint with all of our weights and variables, and it also includes the graph that we built for training, evaluating, and predicting. Keras now natively exports to TensorFlow SavedModel format for serving."
      ]
    },
    {
      "metadata": {
        "id": "qAGVbw5_9swT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tip from markdaoust@ \n",
        "\n",
        "SavedModel failing:  https://github.com/tensorflow/tensorflow/issues/22837"
      ]
    },
    {
      "metadata": {
        "id": "ODi-oNzegAzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "export_dir = tf.contrib.saved_model.save_keras_model(model, 'keras_n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NLNKsuMogA-7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This saved model is a fully-contained serialization of your model, so you can load back in to Python later if you want to retrain or reuse your model."
      ]
    },
    {
      "metadata": {
        "id": "aV6hAnBWkynZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "restored_model = tf.contrib.saved_model.\n",
        "  load_keras_model(export_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YgcvZWVg8HjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Marks Code - Not implemented as of yet\n",
        "The cells below contain suggested changes from markdaoust@ , which have not been succesfully implemented as of yet"
      ]
    },
    {
      "metadata": {
        "id": "xYuPoQ1jg11G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data Import"
      ]
    },
    {
      "metadata": {
        "id": "DdkarT6f8YxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mark suggested that using utils.get_file might be more portable\n",
        "URL = 'https://storage.googleapis.com/amitpatankar-datasets/'\n",
        "data = tf.keras.utils.get_file('heart-disease-uci.zip', URL, extract=True).replace('.zip','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ltiCQMa9LWd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# same dataset as before\n",
        "dataset2 = tf.data.experimental.make_csv_dataset('heart-disease-uci/heart_train.csv', header=True, label_name='target', batch_size=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-Nr2S8F-t_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create lists of various feature types\n",
        "NUMERICAL_COLUMNS = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']\n",
        "STRING_COLUMNS = ['thal']\n",
        "BUCKETIZED_COLUMNS = ['target']\n",
        "CATEGORICAL_COLUMNS = [('sex',2), ('cp',5), ('fbs',2), ('restecg',3), ('exang',2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrJgCab_g412",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Output fc.FeatureLayers as they're introduced\n",
        "\n",
        "Mark suggestion: \n",
        "\n",
        "Given that you're in eager mode, it would be easy to demonstrate the output of `fc.FeatureLayer` for the various column types, as they're introduced, to provide a little more \"show me, don't tell me\""
      ]
    },
    {
      "metadata": {
        "id": "4_8sju8K-E4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_batch = list(dataset.take(1))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJhoqlFT-6YI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "numeric_columns = [fc.numeric_column(header) for header in NUMERICAL_COLUMNS]\n",
        "feature_layer = fc.FeatureLayer(numeric_columns)\n",
        "print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xSTtdJsG-9zh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "identity_columns = [fc.categorical_column_with_identity(header) for header in NUMERICAL_COLUMNS]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "001xEvae--SJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indicator_columns = [fc.indicator_column(col) for col in identity_columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLbuTFdT-_yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one\n",
        "feature_layer = fc.FeatureLayer([indicator_columns[0]])\n",
        "print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0P3QkwBb_Bu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# all\n",
        "feature_layer = fc.FeatureLayer(indicator_columns)\n",
        "print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fmw4840K_H7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_columns = [fc.embedding_column(col, depth) for col in identity_columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tqUV2yex_IVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one\n",
        "feature_layer = fc.FeatureLayer([embedding_columns[0]])\n",
        "print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "va-o5Jil_Kyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# all\n",
        "feature_layer = fc.FeatureLayer(embedding_columns)\n",
        "print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
