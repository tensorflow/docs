{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-records.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "t09eeeR5prIJ"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "GCCk8_dHpuNf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQzaEQuJiW_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using TFRecords and TF Examples"
      ]
    },
    {
      "metadata": {
        "id": "Ac83J0QxjhFt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Example structure as well as the TFRecord format are extremely useful for describing input data in the TensorFlow API. It allows developers to preprocess their data only once for multiple purposes, and allows developers to store their data locally. \n",
        "\n",
        "The [`tf.Example`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto) [protocol buffer](https://developers.google.com/protocol-buffers/) (a protocol buffer is also called a message) is specifically designed for use with TensorFlow, as well as higher-level APIs such as [TFX](https://www.tensorflow.org/tfx/) and [Keras](https://www.tensorflow.org/guide/keras). This notebook will demonstrate how to create, parse, and use the `tf.Example` message, and then store, read, and write this data in the `.tfrecords` format. This tutorial includes an end-to-end example of reading/writing image data as TF Examples in the TFRecord format. \n",
        "\n",
        "Note that, while extremely useful, using these structures is ultimately optional if using the [tf.data API](https://www.tensorflow.org/api_docs/python/tf/data) makes more sense."
      ]
    },
    {
      "metadata": {
        "id": "Ja7sezsmnXph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrdQHgvNijTi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Types In `tf.Example`"
      ]
    },
    {
      "metadata": {
        "id": "lZw57Qrn4CTE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `tf.Example` type is generic enough to accept a wide range of data types. While the following [three types](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L4) of features are compatible with `tf.Example`, most other generic types can be coerced into one of these.\n",
        "\n",
        "1. [`bytes_list`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L65) (the following types can be coerced)\n",
        "\n",
        "  - `string`\n",
        "  - `byte`\n",
        "\n",
        "1. [`float_list`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L68) (the following types can be coerced)\n",
        "\n",
        "  - `float` (`float32`)\n",
        "  - `double` (`float64`)\n",
        "\n",
        "1. [`int64_list`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L65) (the following types can be coerced)\n",
        "\n",
        "  - `bool`\n",
        "  - `enum`\n",
        "  - `int32`\n",
        "  - `uint32`\n",
        "  - `int64`\n",
        "  - `uint64`"
      ]
    },
    {
      "metadata": {
        "id": "_e3g9ExathXP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to convert a standard type to a `tf.Example`-compatible type, we can use the following functions. Each function takes a single input value and returns one of the 3 `list` types above."
      ]
    },
    {
      "metadata": {
        "id": "mbsPOUpVtYxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsMbkkC8xxtB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are some examples of how these functions work. Note the varying input types and the standardizes output types. If the input type for a function does not match one of the coercible types stated above, the function will raise an exception (e.g. `_int64_feature(1.0)` will error out, since `1.0` is a float, so should be used with the `_float_feature` function instead)."
      ]
    },
    {
      "metadata": {
        "id": "hZzyLGr0u73y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(_bytes_featyre(b'test_string'))\n",
        "print(_bytes_feature('test_string'.encode('utf-8')))\n",
        "# Py2 only: print(_bytes_feature('test_bytes'))\n",
        "# Py2 only: print(_bytes_feature(bytes('test_bytes')))\n",
        "# Py3 only: print(_bytes_feature(bytes('test_bytes', 'utf-8')))\n",
        "\n",
        "\n",
        "print(_float_feature(np.exp(1)))\n",
        "\n",
        "print(_int64_feature(True))\n",
        "print(_int64_feature(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laKnw9F3hL-W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating A `tf.Example` Message"
      ]
    },
    {
      "metadata": {
        "id": "b_MEnhxchQPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Suppose you want to create a `tf.Example` message from existing data. In practice, the dataset may come from anywhere, but the procedure of creating the `tf.Example` message from a single observation will be the same. \n",
        "\n",
        "1. Within each observation, each value needs to be converted to one of the 3 compatible types, using one of the functions above. \n",
        "\n",
        "1. We create a map (dictionary) from the feature name string to the encoded feature value produced in #1.\n",
        "\n",
        "1. The map produced in #2 is converted to a [`Features` message](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L85)."
      ]
    },
    {
      "metadata": {
        "id": "4EgFQ2uHtchc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will create a dataset using NumPy. \n",
        "\n",
        "This dataset will have 4 features.\n",
        "- a boolean feature, `False` or `True` with equal probability\n",
        "- a random bytes feature, uniform across the entire support\n",
        "- an integer feature uniformly randomly chosen from `[-10000, 10000)`\n",
        "- a float feature from a standard normal distribution\n",
        "\n",
        "Consider a sample consisting of 10,000 independently and identically distributed observations from each of the above distributions."
      ]
    },
    {
      "metadata": {
        "id": "CnrguFAy3YQv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the number of observations in the dataset\n",
        "n_observations = int(1e4)\n",
        "\n",
        "# boolean feature, encoded as False or True\n",
        "feature0 = np.random.choice([False, True], n_observations)\n",
        "\n",
        "# bytes feature\n",
        "feature1 = np.random.bytes(n_observations)\n",
        "\n",
        "# integer feature, random between -10000 and 10000\n",
        "feature2 = np.random.randint(-10000, 10000, n_observations)\n",
        "\n",
        "# float feature, from a standard normal distribution\n",
        "feature3 = np.random.randn(n_observations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGrscehJr7Jd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each of these features can be coerced into a `tf.Example`-compatible type using one of `_bytes_feature`, `_float_feature`, `_int64_feature`. We can then create a `tf.Example` message from these encoded features."
      ]
    },
    {
      "metadata": {
        "id": "RTCS49Ij_kUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_example(features):\n",
        "  \"\"\"\n",
        "  Creates a tf.Example message ready to be written to a file.\n",
        "  \n",
        "  Inputs:\n",
        "    - features: a 4-list of the values in the observation\n",
        "  \"\"\"\n",
        "  \n",
        "  # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
        "  # data type.\n",
        "  \n",
        "  feature = {\n",
        "      'feature0': _int64_feature(features[0]),\n",
        "      'feature1': _bytes_feature(features[1]),\n",
        "      'feature2': _int64_feature(features[2]),\n",
        "      'feature3': _float_feature(features[3]),\n",
        "  }\n",
        "  \n",
        "  # Create a Features message using tf.train.Example.\n",
        "  \n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XftzX9CN_uGT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, suppose we have a single observation from the dataset, `[False, bytes('example'), -1234, 0.9876]`. We can create and print the `tf.Example` message for this observation using `create_message()`. Each single observation will be written as a `Features` message as per the above. Note that the `tf.Example` [message](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto#L88) is just a wrapper around the `Features` message."
      ]
    },
    {
      "metadata": {
        "id": "N8BtSx2RjYcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is an example observation from the dataset.\n",
        "\n",
        "example_observation = [False, b'example', -1234, 0.9876]\n",
        "\n",
        "print(create_example(example_observation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CKn5uql2lAaN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Writing `tf.Example` Messages To A `.tfrecords` File"
      ]
    },
    {
      "metadata": {
        "id": "LNW_FA-GQWXs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now write the 10,000 observations to the file `test.tfrecords`. Each observation is converted to a `tf.Example` message, then written to file. We can then verify that the file `test.tfrecords` has been created."
      ]
    },
    {
      "metadata": {
        "id": "MKPHzoGv7q44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write the tf.Example observations to test.tfrecords.\n",
        "\n",
        "writer = tf.python_io.TFRecordWriter('test.tfrecords')\n",
        "\n",
        "for i in range(n_observations):\n",
        "  # Note that feature1 (a bytes feature) is indexed [i:i+1] for py3 compatibility\n",
        "  example = create_example([feature0[i], feature1[i:i+1], feature2[i], feature3[i]])\n",
        "  writer.write(example.SerializeToString())\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjdFHHJMpUUo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtQ7k0YWQ1cz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading A `.tfrecords` File"
      ]
    },
    {
      "metadata": {
        "id": "utkozytkQ-2K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Suppose we now want to read this data back, to be input as data into a model.\n",
        "\n",
        "The following example imports the data as is, as a `tf.Example` message. This can be useful to verify that a the file contains the data that we expect. This can also be useful if the input data is stored as TFRecords but you would prefer to input NumPy data (or some other input data type), for example [here](https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays), since this example allows us to read the values themselves.\n",
        "\n",
        "We iterate through the TFRecords in the infile, extract the `tf.Example` message, and can read/store the values within."
      ]
    },
    {
      "metadata": {
        "id": "36ltP9B8OezA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "record_iterator = tf.python_io.tf_record_iterator(path='test.tfrecords')\n",
        "\n",
        "for string_record in record_iterator:\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(string_record)\n",
        "  \n",
        "  print(example)\n",
        "  \n",
        "  # Exit after 1 iteration as this is purely demonstrative.\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3uquiiGTZTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The features of the `example` object (created above of type `tf.Example`) can be accessed using its getters (similarly to any protocol buffer message). `example.features` returns a `repeated feature` message, then getting the `feature` message returns a map of feature name to feature value (stored in Python as a dictionary)."
      ]
    },
    {
      "metadata": {
        "id": "-UNzS7vsUBs0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(dict(example.features.feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1M-WrbqUUVW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From this dictionary, you can get any given value as with a dictionary."
      ]
    },
    {
      "metadata": {
        "id": "2yCBu70IUb2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(example.features.feature['feature3'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dw6_OI9UiNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we can access the value using the getters again."
      ]
    },
    {
      "metadata": {
        "id": "BdDYjDnDUlFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(example.features.feature['feature3'].float_list.value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-Hjmee-fbLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using The `Dataset` Object"
      ]
    },
    {
      "metadata": {
        "id": "o3J5D4gcSy8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also read the `.tfrecords` file into a [`dataset` object](https://www.tensorflow.org/api_docs/python/tf/data/Dataset). More information on consuming the TFRecord object into a Dataset can be found [here](https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data). Using this datatset structure can be useful for standardizing input data and optimizing performance. It is also easier and quicker to use this object."
      ]
    },
    {
      "metadata": {
        "id": "6OjX6UZl-bHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filenames = ['test.tfrecords']\n",
        "dataset = tf.data.TFRecordDataset(filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-6oNzM4luFQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each record in this dataset is an `EagerTensor` type, as [eager execution](https://www.tensorflow.org/guide/eager) was enabled at the start of this notebook. These tensors can be parsed using the function below."
      ]
    },
    {
      "metadata": {
        "id": "zQjbIR1nleiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _parse_function(example_proto):\n",
        " \n",
        "  # Create a dictionary of features.\n",
        "  \n",
        "  features = {\n",
        "      'feature0': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
        "      'feature1': tf.FixedLenFeature([], tf.string, default_value=''),\n",
        "      'feature2': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
        "      'feature3': tf.FixedLenFeature([], tf.float32, default_value=0.0),\n",
        "  }\n",
        "  \n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "  \n",
        "  return tf.parse_single_example(example_proto, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sNV-XclGnOvn"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we can use eager execution to display the observations in the dataset. Note that there are 10,000 observations in this dataset, but we only display the first 10. The data is displayed as a dictionary of features. Each item is a `tf.Tensor`, and the `numpy` element of this tensor displays the value of the feature."
      ]
    },
    {
      "metadata": {
        "id": "x2LT2JCqhoD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for record in dataset.take(10):\n",
        "  print(_parse_function(record))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S0tFDrwdoj3q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading/Writing Image Data"
      ]
    },
    {
      "metadata": {
        "id": "rjN2LFxFpcR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is an example of how to read and write image data using TFRecords. The purpose of this is to show how, end to end, input data (in this case an image) and write the data as a `.tfrecords` file, then read the file back and display the image.\n",
        "\n",
        "This can be useful if, for example, you want to use several models on the same input dataset. Instead of storing the image data raw, it can be preprocessed into the TFRecords format, and that can be used in all further processing and modelling. \n",
        "\n",
        "First, let's download [this](https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg) adorable image of a cat in the snow, and [this](https://upload.wikimedia.org/wikipedia/commons/f/fe/New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg) awesome picture of the Williamsburg Bridge, NYC under construction."
      ]
    },
    {
      "metadata": {
        "id": "BbK8nGxvU9d0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# These imports are relevant for displaying and encoding image strings.\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3a0fmwg8lHdF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -O 'cat_in_snow.jpg' 'https://upload.wikimedia.org/wikipedia/commons/b/b6/Felis_catus-cat_on_snow.jpg'\n",
        "!wget -O 'williamsburg_bridge.jpg' 'https://upload.wikimedia.org/wikipedia/commons/f/fe/New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELE4ueh4o3OM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Azx83ryQEU6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we did earlier, we can now encode the features as types compatible with `tf.Example`. In this case, we will not only store the raw image string as a feature, but we will store the height, width, depth, and an arbitrary `label` feature, which is used when we write the file to distinguish between the cat image and the bridge image. We will use `0` for the cat image, and `1` for the bridge image. "
      ]
    },
    {
      "metadata": {
        "id": "kC4TS1ZEONHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_labels = {\n",
        "    'cat_in_snow.jpg': 0,\n",
        "    'williamsburg_bridge.jpg': 1,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c5njMSYNEhNZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is an example, just using the cat image.\n",
        "\n",
        "file = open('cat_in_snow.jpg', 'rb').read()\n",
        "\n",
        "image_shape = tf.image.decode_jpeg(file).shape\n",
        "image_string = base64.b64encode(file)\n",
        "\n",
        "label = image_labels['cat_in_snow.jpg']\n",
        "\n",
        "# Create a dictionary with features that may be relevant.\n",
        "\n",
        "feature = {\n",
        "    'height': _int64_feature(image_shape[0]),\n",
        "    'width': _int64_feature(image_shape[1]),\n",
        "    'depth': _int64_feature(image_shape[2]),\n",
        "    'label': _int64_feature(label),\n",
        "    'image_raw': _bytes_feature(image_string),\n",
        "}\n",
        "\n",
        "tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "print(tf_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2G_o3O9MN0Qx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that all of the features are now stores in the `tf.Example` message. Now, we functionalize the code above and write the example messages to a file, `images.tfrecords`."
      ]
    },
    {
      "metadata": {
        "id": "qcw06lQCOCZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write the raw image files to images.tfrecords.\n",
        "# First, process the two images into tf.Example messages.\n",
        "# Then, write to a .tfrecords file.\n",
        "\n",
        "writer = tf.python_io.TFRecordWriter('images.tfrecords')\n",
        "\n",
        "for filename, label in image_labels.items():\n",
        "  \n",
        "  file = open(filename, 'rb').read()\n",
        "\n",
        "  image_shape = tf.image.decode_jpeg(file).shape\n",
        "  image_string = base64.b64encode(file)\n",
        "\n",
        "  feature = {\n",
        "      'height': _int64_feature(image_shape[0]),\n",
        "      'width': _int64_feature(image_shape[1]),\n",
        "      'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "  }\n",
        "  \n",
        "  tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJrTe6tHPCfs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJSsCkZLPH6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now have the file `images.tfrecords`. We can now iterate over the records in the file to read back what we wrote. Since, for our use case we will just reproduce the image, the only feature we need is the raw image string. We can extract that using the getters described above, namely `example.features.feature['image_raw'].bytes_list.value[0]`. We also use the labels to determine which record is the cat as opposed to the bridge."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M6Cnfd3cTKHN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "record_iterator = tf.python_io.tf_record_iterator(path='images.tfrecords')\n",
        "\n",
        "# Create a dictionary mapping the image label to the bytes string.\n",
        "\n",
        "image_bytes = {}\n",
        "\n",
        "for string_record in record_iterator:\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(string_record)\n",
        "  \n",
        "  label = example.features.feature['label'].int64_list.value[0]\n",
        "  \n",
        "  image_bytes[label] = example.features.feature['image_raw'].bytes_list.value[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qTkNHH9pid40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we create new blank JPEG files, that we will write the decoded image strings to."
      ]
    },
    {
      "metadata": {
        "id": "eSzTHYZkVGTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('cat_in_snow_from_tfrecords.jpg', 'wb') as f:\n",
        "  f.write(base64.b64decode(image_bytes[image_labels['cat_in_snow.jpg']]))\n",
        "\n",
        "with open('williamsburg_bridge_from_tfrecords.jpg', 'wb') as f:\n",
        "  f.write(base64.b64decode(image_bytes[image_labels['williamsburg_bridge.jpg']]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azilbA7Pjeu2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's display these images! Remember these are not the raw images, these have been encoded as a `.tfrecords` file and then read back into raw image format."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sQq8cG07U6NG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(filename='cat_in_snow_from_tfrecords.jpg', width=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVoldzEVjqIX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(filename='williamsburg_bridge_from_tfrecords.jpg', width=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiP8jBE44mEF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In practice however, it is less practical to work directly with the raw TFRecords format than with the `dataset` object. This is also true for images, where we can easily load image files into a dataset that is ready to use. This example follows the documentation [here](https://www.tensorflow.org/guide/datasets#decoding_image_data_and_resizing_it). We first define another `_parse_function` to parse an image file into a decoded image, then leverage the `from_tensor_slices` method to load these images into a dataset."
      ]
    },
    {
      "metadata": {
        "id": "kG66dtkRpNFQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _parse_function(filename, label):\n",
        "  image_string = tf.read_file(filename)\n",
        "  image_decoded = tf.image.decode_jpeg(image_string)\n",
        "  \n",
        "  return image_decoded, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q25yC0VlwLeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filenames = tf.constant(['cat_in_snow.jpg', 'williamsburg_bridge.jpg'])\n",
        "labels = tf.constant([0, 1])\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "dataset = dataset.map(_parse_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FC8JOld5Ar-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Again using eager execution, we can print the records in the dataset. Each record is a tuple of a part of the image and the label. Each has type `tf.Tensor`, the first is an array of non-trivial shape (as it is part of an image), and the second is the label.\n",
        "\n",
        "From the below, we see that the first record comes from the cat image (as the label is `0`) and the second is from the bridge image (as the label is `1`)."
      ]
    },
    {
      "metadata": {
        "id": "s5zte_y3yGq8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for record in dataset.take(2):\n",
        "  print(record)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
