{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxv6goXm7oGF"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "llMNufAK7nfK"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Byow2J6LaPl"
      },
      "source": [
        "# AutoGraph: Easy control flow for graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGXS3UWBBNoc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/autograph.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGXS3UWBBNoc"
      },
      "source": [
        "> Note: This is an archived TF1 notebook. These are configured\n",
        "to run in TF2's \n",
        "[compatbility mode](https://www.tensorflow.org/guide/migrate)\n",
        "but will run in TF1 as well. To use TF1 in Colab, use the\n",
        "[%tensorflow_version 1.x](https://colab.research.google.com/notebooks/tensorflow_version.ipynb)\n",
        "magic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CydFK2CL7ZHA"
      },
      "source": [
        "[AutoGraph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/) helps you write complicated graph code using normal Python. Behind the scenes, AutoGraph automatically transforms your code into the equivalent [TensorFlow graph code](https://www.tensorflow.org/r1/guide/graphs). AutoGraph already supports much of the Python language, and that coverage continues to grow. For a list of supported Python language features, see the [Autograph capabilities and limitations](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4EKOpw9mObL"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import TensorFlow, AutoGraph, and any supporting modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "794l9aK_BjFq"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT7meGqrZTz9"
      },
      "outputs": [],
      "source": [
        "layers = tf.keras.layers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh1PajmUJMNp"
      },
      "source": [
        "We'll enable  [eager execution](https://www.tensorflow.org/r1/guide/eager) for demonstration purposes, but AutoGraph works in both eager and [graph execution](https://www.tensorflow.org/r1/guide/graphs) environments:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR4lG3hsuWQT"
      },
      "source": [
        "Note: AutoGraph converted code is designed to run during graph execution. When eager exectuon is enabled, use explicit graphs (as this example shows) or `tf.contrib.eager.defun`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohbSnA79mcJV"
      },
      "source": [
        "## Automatically convert Python control flow\n",
        "\n",
        "AutoGraph will convert much of the Python language into the equivalent TensorFlow graph building code.\n",
        "\n",
        "Note: In real applications batching is essential for performance. The best code to convert to AutoGraph is code where the control flow is decided at the _batch_ level. If making decisions at the individual _example_ level, you must index and batch the examples to maintain performance while applying the control flow logic.\n",
        "\n",
        "AutoGraph converts a function like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA3gOodCBkOw"
      },
      "outputs": [],
      "source": [
        "def square_if_positive(x):\n",
        "  if x > 0:\n",
        "    x = x * x\n",
        "  else:\n",
        "    x = 0.0\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LICw4XQFZrhH"
      },
      "source": [
        "To a function that uses graph building:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EMhGUjRZoKQ"
      },
      "outputs": [],
      "source": [
        "print(tf.autograph.to_code(square_if_positive))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpK0m4TCvkJq"
      },
      "source": [
        "Code written for eager execution can run in a `tf.Graph` with the same results, but with the benefits of graph execution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1RtBvoKBxq5"
      },
      "outputs": [],
      "source": [
        "print('Eager results: %2.2f, %2.2f' % (square_if_positive(tf.constant(9.0)),\n",
        "                                       square_if_positive(tf.constant(-9.0))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpk3MxVVv5gn"
      },
      "source": [
        "Generate a graph-version and call it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGjSq0WQvwGs"
      },
      "outputs": [],
      "source": [
        "tf_square_if_positive = tf.autograph.to_graph(square_if_positive)\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  # The result works like a regular op: takes tensors in, returns tensors.\n",
        "  # You can inspect the graph using tf.get_default_graph().as_graph_def()\n",
        "  g_out1 = tf_square_if_positive(tf.constant( 9.0))\n",
        "  g_out2 = tf_square_if_positive(tf.constant(-9.0))\n",
        "  with tf.Session() as sess:\n",
        "    print('Graph results: %2.2f, %2.2f\\n' % (sess.run(g_out1), sess.run(g_out2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-jWmsCmByyw"
      },
      "source": [
        "AutoGraph supports common Python statements like `while`, `for`, `if`, `break`, and `return`, with support for nesting. Compare this function with the complicated graph verson displayed in the following code blocks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toxKBOXbB1ro"
      },
      "outputs": [],
      "source": [
        "# Continue in a loop\n",
        "def sum_even(items):\n",
        "  s = 0\n",
        "  for c in items:\n",
        "    if c % 2 > 0:\n",
        "      continue\n",
        "    s += c\n",
        "  return s\n",
        "\n",
        "print('Eager result: %d' % sum_even(tf.constant([10,12,15,20])))\n",
        "\n",
        "tf_sum_even = tf.autograph.to_graph(sum_even)\n",
        "\n",
        "with tf.Graph().as_default(), tf.Session() as sess:\n",
        "    print('Graph result: %d\\n\\n' % sess.run(tf_sum_even(tf.constant([10,12,15,20]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlyQgxYsYSXr"
      },
      "outputs": [],
      "source": [
        "print(tf.autograph.to_code(sum_even))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUJJ-WTdCGeq"
      },
      "source": [
        "## tf.function\n",
        "\n",
        "Use the `tf.function` decorator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKhFNXDic4Mw"
      },
      "outputs": [],
      "source": [
        "@tf.function(\n",
        "    experimental_autograph_options=tf.autograph.experimental.Feature.EQUALITY_OPERATORS)\n",
        "def fizzbuzz(i, n):\n",
        "  while i < n:\n",
        "    msg = ''\n",
        "    if i % 3 == 0:\n",
        "      msg += 'Fizz'\n",
        "    if i % 5 == 0:\n",
        "      msg += 'Buzz'\n",
        "    if msg == '':\n",
        "      msg = tf.as_string(i)\n",
        "    tf.print(msg)\n",
        "    i += 1\n",
        "  return i\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  final_i = fizzbuzz(tf.constant(10), tf.constant(16))\n",
        "  # The result works like a regular op: takes tensors in, returns tensors.\n",
        "  # You can inspect the graph using tf.get_default_graph().as_graph_def()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(final_i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pkEH6OecW7h"
      },
      "source": [
        "## Examples\n",
        "\n",
        "Let's demonstrate some useful Python language features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axoRAkWi0CQG"
      },
      "source": [
        "### Assert\n",
        "\n",
        "AutoGraph can automatically convert the Python `assert` statement into the equivalent `tf.Assert` code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAOgh62zCPZ4"
      },
      "outputs": [],
      "source": [
        "@tf.function(\n",
        "    experimental_autograph_options=(\n",
        "        tf.autograph.experimental.Feature.ASSERT_STATEMENTS,\n",
        "        tf.autograph.experimental.Feature.EQUALITY_OPERATORS))\n",
        "def inverse(x):\n",
        "  assert x != 0.0, 'Do not pass zero!'\n",
        "  return 1.0 / x\n",
        "\n",
        "with tf.Graph().as_default(), tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(inverse(tf.constant(0.0))))\n",
        "  except tf.errors.InvalidArgumentError as e:\n",
        "    print('Got error message:\\n    %s' % e.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UYgrNtCV9p7"
      },
      "source": [
        "### Print\n",
        "\n",
        "Optionally, you may use the Python `print` function in-graph, when combined with the automatic control dependency management of `tf.function`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehBac9rUR6nh"
      },
      "outputs": [],
      "source": [
        "@tf.function(\n",
        "    experimental_autograph_options=tf.autograph.experimental.Feature.BUILTIN_FUNCTIONS)\n",
        "def count(n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    print(i)\n",
        "    i += 1\n",
        "  return n\n",
        "\n",
        "with tf.Graph().as_default(), tf.Session() as sess:\n",
        "    sess.run(count(tf.constant(5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtpegD_YR6HK"
      },
      "source": [
        "### Lists\n",
        "\n",
        "Append to lists in loops (tensor list ops are automatically created):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABX070KwCczR"
      },
      "outputs": [],
      "source": [
        "@tf.function(\n",
        "    experimental_autograph_options=tf.autograph.experimental.Feature.LISTS)\n",
        "def arange(n):\n",
        "  z = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
        "\n",
        "  for i in tf.range(n):\n",
        "    z.append(i)\n",
        "\n",
        "  return z.stack()\n",
        "\n",
        "\n",
        "with tf.Graph().as_default(), tf.Session() as sess:\n",
        "    print(sess.run(arange(tf.constant(10))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj7am2I_xvTJ"
      },
      "source": [
        "### Nested control flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yyNOf-Twr6s"
      },
      "outputs": [],
      "source": [
        "@tf.function(\n",
        "    experimental_autograph_options=tf.autograph.experimental.Feature.EQUALITY_OPERATORS)\n",
        "def nearest_odd_square(x):\n",
        "  if x > 0:\n",
        "    x = x * x\n",
        "    if x % 2 == 0:\n",
        "      x = x + 1\n",
        "  return x\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(nearest_odd_square(tf.constant(4))))\n",
        "    print(sess.run(nearest_odd_square(tf.constant(5))))\n",
        "    print(sess.run(nearest_odd_square(tf.constant(6))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXAxjeBr1qWK"
      },
      "source": [
        "### While loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucmZyQVL03bF"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def square_until_stop(x, y):\n",
        "  while x < y:\n",
        "    x = x * x\n",
        "  return x\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(square_until_stop(tf.constant(4), tf.constant(100))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N1mz7sNY87N"
      },
      "source": [
        "### For loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFk2fszrY8af"
      },
      "outputs": [],
      "source": [
        "@tf.function(\n",
        "    experimental_autograph_options=tf.autograph.experimental.Feature.LISTS)\n",
        "def squares(nums):\n",
        "\n",
        "  result = tf.TensorArray(tf.int64, size=0, dynamic_size=True)\n",
        "  \n",
        "  for num in nums:\n",
        "    result.append(num * num)\n",
        "\n",
        "  return result.stack()\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(squares(tf.constant(np.arange(10)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXB0Zbwl13PY"
      },
      "source": [
        "### Break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sjaFcL717Ig"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def argwhere_cumsum(x, threshold):\n",
        "  current_sum = 0.0\n",
        "  idx = 0\n",
        "  for i in tf.range(len(x)):\n",
        "    idx = i\n",
        "    if current_sum >= threshold:\n",
        "      break\n",
        "    current_sum += x[i]\n",
        "  return idx\n",
        "\n",
        "N = 10\n",
        "with tf.Graph().as_default():\n",
        "  with tf.Session() as sess:\n",
        "    idx = argwhere_cumsum(tf.ones(N), tf.constant(float(N/2)))\n",
        "    print(sess.run(idx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW3nMVABOGaN"
      },
      "source": [
        "## Interoperation with `tf.Keras`\n",
        "\n",
        "It's easy to integrate `tf.autograph` with `tf.keras`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHpr4VlWPEiS"
      },
      "source": [
        "### Stateless functions\n",
        "\n",
        "For stateless functions, like `collatz` shown below, the easiest way to include them in a keras model is to wrap them up as a layer using `tf.keras.layers.Lambda`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1O12C8FOE5U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "@tf.function(\n",
        "    experimental_autograph_options=(\n",
        "        tf.autograph.experimental.Feature.ASSERT_STATEMENTS,\n",
        "        tf.autograph.experimental.Feature.EQUALITY_OPERATORS,\n",
        "        ))\n",
        "def collatz(x):\n",
        "  x = tf.reshape(x,())\n",
        "  assert x > 0\n",
        "  n = tf.convert_to_tensor((0,))\n",
        "  while x != 1:\n",
        "    n += 1\n",
        "    if x % 2 == 0:\n",
        "      x = x // 2\n",
        "    else:\n",
        "      x = 3 * x + 1\n",
        "\n",
        "  return n\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Lambda(collatz, input_shape=(1,), output_shape=())\n",
        "  ])\n",
        "\n",
        "  result = model.predict(np.array([6171]))\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neKBM7AfOEv8"
      },
      "source": [
        "### Advanced Custom Models\n",
        "\n",
        "<!--TODO(markdaoust) link to full examples  or these referenced models.-->\n",
        "\n",
        "For subclasses of Keras models, the easiest way is to convert their `call` method. See the [TensorFlow Keras guide](https://tensorflow.org/r1/guide/keras#build_advanced_models) for details on how to build on these classes.\n",
        "\n",
        "Here is a simple example of the [stochastic network depth](https://arxiv.org/abs/1603.09382) technique :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2_tocmEOEWF"
      },
      "outputs": [],
      "source": [
        "# `K` is used to check if we're in train or test mode.\n",
        "K = tf.keras.backend\n",
        "\n",
        "class StochasticNetworkDepth(tf.keras.Sequential):\n",
        "  def __init__(self, layers, pfirst=1.0, plast=0.5,**kwargs):\n",
        "    self.pfirst = pfirst\n",
        "    self.plast = plast\n",
        "    super(StochasticNetworkDepth, self).__init__(layers,**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.depth = len(self.layers)\n",
        "    self.plims = np.linspace(self.pfirst, self.plast, self.depth + 1)[:-1]\n",
        "    super(StochasticNetworkDepth, self).build(input_shape.as_list())\n",
        "\n",
        "  def call(self, inputs):\n",
        "    training = tf.cast(K.learning_phase(), dtype=bool)\n",
        "    if not training:\n",
        "      count = self.depth\n",
        "      return super(StochasticNetworkDepth, self).call(inputs), count\n",
        "\n",
        "    p = tf.random_uniform((self.depth,))\n",
        "\n",
        "    keeps = (p <= self.plims)\n",
        "    x = inputs\n",
        "\n",
        "    count = tf.reduce_sum(tf.cast(keeps, tf.int32))\n",
        "    for i in range(self.depth):\n",
        "      if keeps[i]:\n",
        "        x = self.layers[i](x)\n",
        "\n",
        "    # return both the final-layer output and the number of layers executed.\n",
        "    return x, count\n",
        "\n",
        "StochasticNetworkDepth.call = tf.autograph.to_graph(StochasticNetworkDepth.call)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbCzHrKlOEOR"
      },
      "source": [
        "Let's try it on mnist-shaped data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxahwlVfOELA"
      },
      "outputs": [],
      "source": [
        "train_batch = np.random.randn(64, 28, 28, 1).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_hw-qPOEH9"
      },
      "source": [
        "Build a simple stack of `conv` layers, in the stochastic depth model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NiXFOO6OEE1"
      },
      "outputs": [],
      "source": [
        "with tf.Graph().as_default() as g:\n",
        "  model = StochasticNetworkDepth(\n",
        "      [\n",
        "        layers.Conv2D(filters=16, activation=tf.nn.relu,\n",
        "                  kernel_size=(3, 3), padding='same')\n",
        "        for n in range(20)\n",
        "      ],\n",
        "      pfirst=1.0, plast=0.5\n",
        "  )\n",
        "\n",
        "  model.build(tf.TensorShape((None, None, None, 1)))\n",
        "\n",
        "  init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM3g_v7mvrkg"
      },
      "source": [
        "Now test it to ensure it behaves as expected in train and test modes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tdmuh5Zvm3D"
      },
      "outputs": [],
      "source": [
        "# Use an explicit session here so we can set the train/test switch, and\n",
        "# inspect the layer count returned by `call`\n",
        "with tf.Session(graph=g) as sess:\n",
        "  init.run()\n",
        "\n",
        "  for phase, name in enumerate(['test','train']):\n",
        "    K.set_learning_phase(phase)\n",
        "    result, count = model(tf.convert_to_tensor(train_batch, dtype=tf.float32))\n",
        "\n",
        "    result1, count1 = sess.run((result, count))\n",
        "    result2, count2 = sess.run((result, count))\n",
        "\n",
        "    delta = (result1 - result2)\n",
        "    print(name, \"sum abs delta: \", abs(delta).mean())\n",
        "    print(\"    layers 1st call: \", count1)\n",
        "    print(\"    layers 2nd call: \", count2)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfnJjm0Bm0B"
      },
      "source": [
        "## Advanced example: An in-graph training loop\n",
        "\n",
        "The previous section showed that AutoGraph can be used inside Keras layers and models. Keras models can also be used in AutoGraph code.\n",
        "\n",
        "Since writing control flow in AutoGraph is easy, running a training loop in a TensorFlow graph should also be easy.\n",
        "\n",
        "This example shows how to train a simple Keras model on MNIST with the entire training process—loading batches, calculating gradients, updating parameters, calculating validation accuracy, and repeating until convergence—is performed in-graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em5dzSUOtLRP"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqoxumv0ssQW"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znmy4l8ntMvW"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe-erWQdBoC5"
      },
      "outputs": [],
      "source": [
        "def mlp_model(input_shape):\n",
        "  model = tf.keras.Sequential((\n",
        "      tf.keras.layers.Dense(100, activation='relu', input_shape=input_shape),\n",
        "      tf.keras.layers.Dense(100, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')))\n",
        "  model.build()\n",
        "  return model\n",
        "\n",
        "\n",
        "def predict(m, x, y):\n",
        "  x = tf.to_float(x) / 255.0\n",
        "  y = tf.one_hot(tf.squeeze(y), 10)\n",
        "  y_p = m(tf.reshape(x, (-1, 28 * 28)))\n",
        "  losses = tf.keras.losses.categorical_crossentropy(y, y_p)\n",
        "  l = tf.reduce_mean(losses)\n",
        "  accuracies = tf.keras.metrics.categorical_accuracy(y, y_p)\n",
        "  accuracy = tf.reduce_mean(accuracies)\n",
        "  return l, accuracy\n",
        "\n",
        "\n",
        "def fit(m, x, y, opt):\n",
        "  l, accuracy = predict(m, x, y)\n",
        "  # Autograph automatically adds the necessary `tf.control_dependencies` here.\n",
        "  # (Without them nothing depends on `opt.minimize`, so it doesn't run.)\n",
        "  # This makes it much more like eager-code.\n",
        "  opt.minimize(l)\n",
        "  return l, accuracy\n",
        "\n",
        "\n",
        "def setup_mnist_data(is_training, batch_size):\n",
        "  if is_training:\n",
        "    ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    ds = ds.shuffle(batch_size * 10)\n",
        "  else:\n",
        "    ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeYV6mKnJGMr"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xtg_MMhJETd"
      },
      "outputs": [],
      "source": [
        "def train(train_ds, test_ds, learning_rate, max_steps):\n",
        "  m = mlp_model((28 * 28,))\n",
        "  opt = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "  train_losses = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n",
        "  test_losses = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n",
        "  train_accuracies = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n",
        "  test_accuracies = tf.TensorArray(tf.float32, size=0, dynamic_size=True, element_shape=())\n",
        "\n",
        "  # This entire training loop will be run in-graph.\n",
        "  i = tf.constant(0)\n",
        "  for (train_x, train_y), (test_x, test_y) in tf.data.Dataset.zip((train_ds, test_ds)):\n",
        "    step_train_loss, step_train_accuracy = fit(m, train_x, train_y, opt)\n",
        "    step_test_loss, step_test_accuracy = predict(m, test_x, test_y)\n",
        "    if i % 50 == 0:\n",
        "      print('Step', i, 'train loss:', step_train_loss, 'test loss:',\n",
        "            step_test_loss, 'train accuracy:', step_train_accuracy,\n",
        "            'test accuracy:', step_test_accuracy)\n",
        "    train_losses.append(step_train_loss)\n",
        "    test_losses.append(step_test_loss)\n",
        "    train_accuracies.append(step_train_accuracy)\n",
        "    test_accuracies.append(step_test_accuracy)\n",
        "\n",
        "    i += 1\n",
        "    if i >= max_steps:\n",
        "      break\n",
        "\n",
        "  # We've recorded our loss values and accuracies\n",
        "  # to a list in a graph with AutoGraph's help.\n",
        "  # In order to return the values as a Tensor,\n",
        "  # we need to stack them before returning them.\n",
        "  return (train_losses.stack(), test_losses.stack(),\n",
        "          train_accuracies.stack(), test_accuracies.stack())\n",
        "  \n",
        "train = tf.autograph.to_graph(\n",
        "    train,\n",
        "    experimental_optional_features=(\n",
        "        tf.autograph.experimental.Feature.LISTS,\n",
        "        tf.autograph.experimental.Feature.BUILTIN_FUNCTIONS,\n",
        "        tf.autograph.experimental.Feature.EQUALITY_OPERATORS,\n",
        "        tf.autograph.experimental.Feature.AUTO_CONTROL_DEPS))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsHLDZniauLV"
      },
      "source": [
        "Now build the graph and run the training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYh6MSZyJOag"
      },
      "outputs": [],
      "source": [
        "with tf.Graph().as_default() as g:\n",
        "  learning_rate = 0.005\n",
        "  max_steps=500\n",
        "\n",
        "  train_ds = setup_mnist_data(True, 50)\n",
        "  test_ds = setup_mnist_data(False, 1000)\n",
        "  (train_losses, test_losses, train_accuracies,\n",
        "   test_accuracies) = train(train_ds, test_ds, learning_rate, max_steps)\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session(graph=g) as sess:\n",
        "  sess.run(init)\n",
        "  (train_losses, test_losses, train_accuracies,\n",
        "   test_accuracies) = sess.run([train_losses, test_losses, train_accuracies,\n",
        "                                test_accuracies])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzifaV9PGnH6"
      },
      "outputs": [],
      "source": [
        "plt.title('MNIST train/test losses')\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Training step')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "plt.title('MNIST train/test accuracies')\n",
        "plt.plot(train_accuracies, label='train accuracy')\n",
        "plt.plot(test_accuracies, label='test accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('Training step')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "autograph.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
